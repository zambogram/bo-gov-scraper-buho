# FASE 4: OCR y Extracci√≥n de Texto - Documentaci√≥n T√©cnica

## üìã Resumen

La FASE 4 implementa un sistema completo de extracci√≥n de texto de documentos PDF, capaz de procesar tanto PDFs digitales como escaneados usando t√©cnicas de OCR.

## üéØ Objetivos Cumplidos

- ‚úÖ Detecci√≥n autom√°tica de tipo de PDF (escaneado vs. digital)
- ‚úÖ Extracci√≥n de texto de PDFs digitales
- ‚úÖ OCR para PDFs escaneados usando Tesseract
- ‚úÖ Limpieza y normalizaci√≥n de texto
- ‚úÖ Almacenamiento estructurado de textos extra√≠dos
- ‚úÖ Generaci√≥n/actualizaci√≥n de CSV con metadatos
- ‚úÖ Sistema de logging detallado

## üîç M√©todo de Detecci√≥n de PDFs Escaneados

### Estrategia Principal

La funci√≥n `is_scanned_pdf()` utiliza un enfoque pragm√°tico basado en la cantidad de texto extra√≠ble:

```python
def is_scanned_pdf(pdf_path: str, threshold: int = 100) -> bool:
    """
    Detecta si un PDF es escaneado o digital mediante an√°lisis de contenido de texto.
    """
```

### Proceso de Detecci√≥n (Paso a Paso)

1. **Apertura del PDF con PyMuPDF (fitz)**
   - Se utiliza PyMuPDF por su velocidad y eficiencia
   - Se verifica que el PDF no est√© vac√≠o

2. **Extracci√≥n de Texto de la Primera P√°gina**
   - Se extrae el texto de solo la primera p√°gina para eficiencia
   - Se usa `page.get_text()` que obtiene todo el texto visible

3. **Limpieza y Conteo**
   - Se eliminan todos los espacios en blanco: `re.sub(r'\s+', '', text)`
   - Se cuentan los caracteres restantes

4. **Comparaci√≥n con Umbral**
   - **Umbral por defecto: 100 caracteres**
   - Si `caracteres < 100` ‚Üí PDF escaneado (imagen)
   - Si `caracteres >= 100` ‚Üí PDF digital (texto)

### Justificaci√≥n del M√©todo

**¬øPor qu√© este enfoque?**

- **Simplicidad**: Un solo an√°lisis r√°pido vs. an√°lisis complejo de im√°genes
- **Eficiencia**: Solo lee la primera p√°gina, no todo el documento
- **Precisi√≥n**: PDFs escaneados t√≠picamente tienen 0 caracteres o muy pocos (metadatos)
- **Velocidad**: PyMuPDF es una de las librer√≠as m√°s r√°pidas para este an√°lisis

**¬øPor qu√© umbral de 100 caracteres?**

- PDFs digitales t√≠picamente tienen >500 caracteres en la primera p√°gina
- PDFs escaneados suelen tener 0-20 caracteres (solo metadatos)
- 100 caracteres es un punto medio seguro que minimiza falsos positivos/negativos

### Casos Especiales

- **PDFs h√≠bridos**: Se tratan como digitales si tienen suficiente texto
- **PDFs corruptos**: Se asume escaneado y se aplica OCR (fallback seguro)
- **PDFs con im√°genes y texto**: Si tienen >100 caracteres ‚Üí digital

## üõ†Ô∏è Funciones Principales

### 1. `is_scanned_pdf(pdf_path, threshold=100)`
Detecta tipo de PDF.

**Par√°metros:**
- `pdf_path`: Ruta al archivo PDF
- `threshold`: Umbral de caracteres (default: 100)

**Retorna:** `bool` - True si es escaneado, False si es digital

### 2. `extract_text_scanned(pdf_path, lang='spa')`
Extrae texto usando OCR con Tesseract.

**Proceso:**
1. Convierte cada p√°gina del PDF a imagen (pdf2image)
2. Aplica OCR con Tesseract en espa√±ol
3. Concatena textos de todas las p√°ginas

**Par√°metros:**
- `pdf_path`: Ruta al PDF escaneado
- `lang`: Idioma para OCR (default: espa√±ol)

**Retorna:** `str` - Texto extra√≠do

### 3. `extract_text_digital(pdf_path)`
Extrae texto de PDF digital.

**Proceso:**
1. Abre PDF con PyMuPDF
2. Itera por cada p√°gina extrayendo texto
3. Fallback a pdfminer.six si PyMuPDF falla

**Retorna:** `str` - Texto extra√≠do

### 4. `clean_text(raw_text)`
Limpia y normaliza texto extra√≠do.

**Operaciones:**
- Elimina caracteres de control
- Normaliza espacios m√∫ltiples
- Limita saltos de l√≠nea consecutivos (m√°x 2)
- Elimina espacios al inicio/final de l√≠neas

**Retorna:** `str` - Texto limpio

### 5. `save_text(pdf_path, text, output_dir)`
Guarda texto en archivo .txt.

**Retorna:** `str` - Ruta del archivo creado

### 6. `process_pdf(pdf_path, output_dir)`
**Funci√≥n principal** que orquesta todo el pipeline.

**Pipeline:**
```
PDF ‚Üí Detectar tipo ‚Üí Extraer texto ‚Üí Limpiar ‚Üí Guardar ‚Üí Metadatos
```

**Retorna:** `dict` con resultados completos

### 7. `process_multiple_pdfs(pdf_list, output_dir)`
Procesa m√∫ltiples PDFs con logging detallado.

### 8. `print_summary(results)`
Imprime resumen formateado de resultados.

## üìä Estructura de Datos

### Resultado de `process_pdf()`

```python
{
    'pdf_path': str,              # Ruta original del PDF
    'is_scanned': bool,           # True si es escaneado
    'ocr_usado': bool,            # True si se us√≥ OCR
    'paginas': int,               # N√∫mero de p√°ginas
    'caracteres_extraidos': int,  # Total de caracteres
    'texto_extraido': bool,       # True si hubo √©xito
    'txt_path': str,              # Ruta del .txt generado
    'error': str                  # Mensaje de error (si hay)
}
```

### CSV de Metadatos

Columnas generadas/actualizadas:

| Columna | Tipo | Descripci√≥n |
|---------|------|-------------|
| `pdf_filename` | str | Nombre del archivo PDF |
| `pdf_path` | str | Ruta completa al PDF |
| `texto_extraido` | str | 's√≠' o 'no' |
| `ocr_usado` | str | 's√≠' o 'no' |
| `paginas` | int | Cantidad de p√°ginas |
| `caracteres_extraidos` | int | Total de caracteres |
| `ruta_texto` | str | Ruta al .txt generado |
| `tipo_pdf` | str | 'escaneado' o 'digital' |
| `error` | str | Mensaje de error (vac√≠o si OK) |

## üìÅ Estructura de Directorios

```
data/
‚îú‚îÄ‚îÄ pdfs/           # PDFs originales a procesar
‚îú‚îÄ‚îÄ text/           # Textos extra√≠dos (.txt)
‚îî‚îÄ‚îÄ csv/            # CSVs con metadatos
    ‚îî‚îÄ‚îÄ documentos_metadata.csv
```

## üöÄ Uso del Sistema

### Instalaci√≥n de Dependencias

```bash
pip install -r requirements.txt
```

**Nota importante:** Tesseract OCR debe estar instalado en el sistema:

```bash
# Ubuntu/Debian
sudo apt-get install tesseract-ocr tesseract-ocr-spa

# macOS
brew install tesseract tesseract-lang

# Windows
# Descargar desde: https://github.com/UB-Mannheim/tesseract/wiki
```

### Ejecuci√≥n

```bash
# Colocar PDFs en data/pdfs/
python main.py
```

### Ejemplo de Salida

```
======================================================================
FASE 4: OCR Y EXTRACCI√ìN DE TEXTO DE PDFs
Sistema de procesamiento de documentos del Estado Boliviano
======================================================================

Buscando PDFs en: data/pdfs
‚úÖ Encontrados 3 PDFs para procesar

============================================================
Procesando PDF 1/3: decreto_123.pdf
============================================================
INFO:__main__:PDF: decreto_123.pdf - Caracteres: 1543 - Tipo: DIGITAL
INFO:__main__:Extrayendo texto digital de: decreto_123.pdf
INFO:__main__:Extracci√≥n digital completada: 15234 caracteres
INFO:__main__:Texto guardado en: data/text/decreto_123.txt

...

======================================================================
RESUMEN DE EXTRACCI√ìN DE TEXTO
======================================================================

1. decreto_123.pdf
   Tipo: DIGITAL
   OCR usado: NO
   P√°ginas: 5
   Caracteres extra√≠dos: 15,234
   Texto extra√≠do: S√ç
   Archivo generado: data/text/decreto_123.txt

...

Estad√≠sticas:
  Total PDFs procesados: 3
  PDFs digitales: 2
  PDFs escaneados: 1
  OCR aplicado: 1
  Extracciones exitosas: 3/3
======================================================================
```

## üîß Configuraci√≥n Avanzada

### Ajustar Umbral de Detecci√≥n

Editar en `text_extractor.py`:

```python
# Para PDFs con poco texto leg√≠timo
is_scanned = is_scanned_pdf(pdf_path, threshold=50)

# Para ser m√°s estricto
is_scanned = is_scanned_pdf(pdf_path, threshold=200)
```

### Cambiar Idioma de OCR

```python
# Para documentos en ingl√©s
text = extract_text_scanned(pdf_path, lang='eng')

# Para documentos multiidioma
text = extract_text_scanned(pdf_path, lang='spa+eng+que')
```

## üé® Integraci√≥n con Pipeline Completo

Este m√≥dulo est√° dise√±ado para integrarse f√°cilmente:

```python
from scraper.text_extractor import process_pdf

# Procesar un PDF del scraper
result = process_pdf('data/pdfs/documento.pdf', 'data/text')

# Usar resultados en an√°lisis posterior (FASE 5)
if result['texto_extraido']:
    with open(result['txt_path'], 'r') as f:
        texto = f.read()
        # Aplicar an√°lisis jur√≠dico, NLP, etc.
```

## üìà Mejoras Futuras (Preparaci√≥n FASE 5)

- ‚úÖ Textos limpios y normalizados listos para NLP
- ‚úÖ Metadatos estructurados en CSV
- ‚úÖ Identificaci√≥n de tipo de documento
- üîú An√°lisis jur√≠dico de contenido
- üîú Extracci√≥n de entidades (fechas, n√∫meros de ley, etc.)
- üîú Clasificaci√≥n autom√°tica de documentos
- üîú B√∫squeda sem√°ntica en corpus

## ‚ö†Ô∏è Limitaciones Conocidas

1. **OCR de calidad variable**: Depende de la calidad del escaneo
2. **Lento para PDFs grandes**: OCR puede tomar minutos por documento
3. **Requiere Tesseract instalado**: Dependencia del sistema
4. **Memoria**: PDFs muy grandes pueden consumir mucha RAM

## ü§ù Contribuci√≥n

Este m√≥dulo es parte del proyecto B√öHO de an√°lisis de documentos del Estado Boliviano.

---

**Autor:** Sistema B√öHO
**Fecha:** Noviembre 2025
**Versi√≥n:** 1.0.0
