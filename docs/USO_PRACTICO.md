# üìò Gu√≠a de Uso Pr√°ctico - B√öHO

Esta gu√≠a te muestra c√≥mo usar el sistema B√öHO paso a paso, con ejemplos reales y casos de uso pr√°cticos.

---

## üìã Tabla de Contenidos

1. [Instalaci√≥n Completa](#1-instalaci√≥n-completa)
2. [Primer Uso](#2-primer-uso)
3. [Explorando el Cat√°logo](#3-explorando-el-cat√°logo)
4. [Usando la UI Web](#4-usando-la-ui-web)
5. [Flujos de Trabajo Recomendados](#5-flujos-de-trabajo-recomendados)
6. [Casos de Uso Reales](#6-casos-de-uso-reales)
7. [Troubleshooting](#7-troubleshooting)

---

## 1. Instalaci√≥n Completa

### Paso 1: Requisitos previos

Aseg√∫rate de tener instalado:

```bash
python --version  # Debe ser 3.9 o superior
pip --version
```

### Paso 2: Clonar y configurar

```bash
# Clonar el repositorio
git clone <url-del-repo>
cd bo-gov-scraper-buho

# Instalar dependencias
pip install -r requirements.txt

# Verificar instalaci√≥n
python main.py --version
```

### Paso 3: Primer test

```bash
# Validar que el cat√°logo funciona
python main.py validate

# Deber√≠as ver:
# ‚úì Cat√°logo v√°lido - sin errores
```

---

## 2. Primer Uso

### Ver todos los sitios disponibles

```bash
python main.py list
```

**Salida esperada:**
```
Total de sitios: 15

‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ ID            ‚îÇ Nombre                           ‚îÇ Tipo  ‚îÇ Ni ‚îÇ Pri ‚îÇ Estado ‚îÇ Docs ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ gaceta_ofic...‚îÇ Gaceta Oficial del Estado...     ‚îÇ norm  ‚îÇ na ‚îÇ  1  ‚îÇ ‚è≥ pen ‚îÇ    0 ‚îÇ
‚îÇ tsj_genesis   ‚îÇ Tribunal Supremo...              ‚îÇ juri  ‚îÇ na ‚îÇ  1  ‚îÇ ‚è≥ pen ‚îÇ    0 ‚îÇ
...
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

### Ver solo sitios prioritarios (Ola 1)

```bash
python main.py list --prioridad 1
```

**Resultado:** Solo ver√°s los 5 sitios de prioridad m√°xima (MVP).

### Informaci√≥n detallada de un sitio

```bash
python main.py info gaceta_oficial
```

**Salida esperada:**
```
Gaceta Oficial del Estado Plurinacional de Bolivia

‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ üìã Informaci√≥n B√°sica ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ    ID:            gaceta_oficial                                             ‚îÇ
‚îÇ    Nivel:         nacional                                                   ‚îÇ
‚îÇ    Tipo:          normativa                                                  ‚îÇ
‚îÇ    Prioridad:     1 (MVP)                                                    ‚îÇ
‚îÇ    Estado:        ‚è≥ pendiente                                               ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ üîó URLs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ    URL Base:         http://www.gacetaoficialdebolivia.gob.bo                ‚îÇ
‚îÇ    URL B√∫squeda:     ...                                                     ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
...
```

### Ver estad√≠sticas generales

```bash
python main.py stats
```

**Muestra:**
- Total de sitios catalogados
- Cu√°ntos est√°n implementados vs pendientes
- Distribuci√≥n por prioridad, nivel y tipo
- Total de documentos y art√≠culos procesados

---

## 3. Explorando el Cat√°logo

### Filtros avanzados

#### Por tipo de fuente

```bash
# Solo normativa
python main.py list --tipo normativa

# Solo jurisprudencia
python main.py list --tipo jurisprudencia

# Solo reguladores
python main.py list --tipo regulador
```

#### Por nivel gubernamental

```bash
# Solo sitios nacionales
python main.py list --nivel nacional

# Solo departamentales
python main.py list --nivel departamental

# Solo municipales
python main.py list --nivel municipal
```

#### Por estado de implementaci√≥n

```bash
# Sitios ya implementados
python main.py list --estado implementado

# Sitios pendientes
python main.py list --estado pendiente

# Sitios en desarrollo
python main.py list --estado en_progreso
```

#### Combinando filtros

```bash
# Normativa nacional prioritaria pendiente
python main.py list --tipo normativa --nivel nacional --prioridad 1 --estado pendiente
```

### Salida en JSON

```bash
# Para procesamiento program√°tico
python main.py list --prioridad 1 --json > ola1_sites.json
python main.py info tcp --json > tcp_info.json
python main.py stats --json > catalog_stats.json
```

---

## 4. Usando la UI Web

### Iniciar Streamlit

```bash
streamlit run app/streamlit_app.py
```

Se abrir√° autom√°ticamente en tu navegador: `http://localhost:8501`

### Navegaci√≥n

#### P√°gina Dashboard (üè†)

- **M√©tricas clave:** Total de sitios, implementados, documentos, art√≠culos
- **Gr√°ficos:** Distribuci√≥n por prioridad, nivel y tipo
- **Sitios Ola 1:** Vista r√°pida de los sitios prioritarios

#### P√°gina Sitios (üìã)

1. **Sidebar:** Usa los filtros para refinar la b√∫squeda
   - Prioridad: Todas, 1, 2, 3
   - Estado: Todos, Implementado, Pendiente, etc.
   - Nivel: Todos, Nacional, Departamental, Municipal
   - Tipo: Todos, Normativa, Jurisprudencia, Regulador

2. **Tarjetas de sitios:** Cada sitio muestra:
   - Nombre y estado
   - Documentos y art√≠culos procesados
   - Bot√≥n "Ver detalles" (expandible)
   - Botones de acci√≥n (Scrape, Info)

3. **Detalles expandibles:** Click en "Ver detalles" para ver:
   - URLs completas
   - Caracter√≠sticas t√©cnicas
   - Tipos de documentos
   - Notas espec√≠ficas

#### P√°gina Estad√≠sticas (üìä)

- **Resumen general:** M√©tricas agregadas
- **Tabla completa:** Todos los sitios con sus datos
- **Exportar CSV:** Bot√≥n para descargar la tabla

#### P√°gina Configuraci√≥n (‚öôÔ∏è)

- **Validar cat√°logo:** Verifica la integridad
- **Rutas del proyecto:** Informaci√≥n de directorios

---

## 5. Flujos de Trabajo Recomendados

### Flujo 1: Exploraci√≥n Inicial

**Objetivo:** Familiarizarte con el sistema.

```bash
# 1. Ver todos los sitios
python main.py list

# 2. Ver solo prioridad 1
python main.py list --prioridad 1

# 3. Ver detalles de un sitio interesante
python main.py info gaceta_oficial
python main.py info tcp
python main.py info asfi

# 4. Ver estad√≠sticas generales
python main.py stats

# 5. Validar que todo est√© bien
python main.py validate
```

### Flujo 2: An√°lisis de un Tipo Espec√≠fico

**Objetivo:** Explorar solo sitios de jurisprudencia.

```bash
# 1. Listar sitios de jurisprudencia
python main.py list --tipo jurisprudencia

# 2. Ver detalles de cada uno
python main.py info tsj_genesis
python main.py info tcp
python main.py info ait

# 3. Exportar a JSON para an√°lisis
python main.py list --tipo jurisprudencia --json > jurisprudencia_sites.json
```

### Flujo 3: Planificaci√≥n de Scraping

**Objetivo:** Preparar el scraping de sitios de Ola 1.

```bash
# 1. Ver sitios Ola 1
python main.py list --prioridad 1

# 2. Revisar caracter√≠sticas t√©cnicas
python main.py info gaceta_oficial  # requiere_selenium: true
python main.py info tcp              # requiere_selenium: true
python main.py info asfi             # requiere_selenium: false

# 3. Probar comando demo (cuando est√© implementado)
python main.py demo-ola1 --limit 3
```

### Flujo 4: Monitoreo Continuo

**Objetivo:** Revisar el estado del sistema.

```bash
# 1. Validar integridad
python main.py validate

# 2. Ver estad√≠sticas
python main.py stats

# 3. Ver sitios implementados
python main.py list --estado implementado

# 4. Verificar √∫ltima actualizaci√≥n de cada sitio
python main.py stats --json | jq '.total_documentos'
```

---

## 6. Casos de Uso Reales

### Caso 1: "Necesito scrapear toda la normativa nacional"

**Pasos:**

```bash
# 1. Identificar sitios de normativa nacional
python main.py list --tipo normativa --nivel nacional

# Resultado:
# - gaceta_oficial (Prioridad 1)
# - silep (Prioridad 2)
# - lexivox (Prioridad 3)

# 2. Ver detalles de cada uno
python main.py info gaceta_oficial
python main.py info silep

# 3. Cuando est√©n implementados, ejecutar:
python main.py scrape gaceta_oficial --limit 100
python main.py scrape silep --limit 100

# 4. Exportar datos
# (Comando de exportaci√≥n - pr√≥ximamente)
```

### Caso 2: "Solo me interesa jurisprudencia del TCP"

**Pasos:**

```bash
# 1. Ver info del TCP
python main.py info tcp

# 2. Verificar estado
# Estado: pendiente ‚Üí Esperar implementaci√≥n

# 3. Cuando est√© implementado:
python main.py scrape tcp --limit 50

# 4. Exportar solo TCP
# (Comando de exportaci√≥n espec√≠fica - pr√≥ximamente)
```

### Caso 3: "Necesito datos de reguladores financieros"

**Pasos:**

```bash
# 1. Listar reguladores
python main.py list --tipo regulador

# 2. Identificar financieros: ASFI, APS
python main.py info asfi
python main.py info aps

# 3. Scrapear ambos
python main.py scrape asfi --limit 100
python main.py scrape aps --limit 100

# 4. Consolidar exportaci√≥n
# (Comando de exportaci√≥n consolidada - pr√≥ximamente)
```

### Caso 4: "Quiero un dashboard visual para mi equipo"

**Pasos:**

```bash
# 1. Iniciar UI Streamlit
streamlit run app/streamlit_app.py

# 2. Compartir URL con tu equipo
# http://localhost:8501 (o tu IP si expones el puerto)

# 3. Usar filtros en el sidebar para explorar

# 4. Exportar estad√≠sticas como CSV desde la UI
```

---

## 7. Troubleshooting

### Problema: "Cat√°logo no encontrado"

**Error:**
```
FileNotFoundError: Cat√°logo no encontrado en: config/sites_catalog.yaml
```

**Soluci√≥n:**
```bash
# Verificar que est√°s en el directorio del proyecto
pwd

# Debe mostrar: .../bo-gov-scraper-buho

# Si no, navega al directorio correcto
cd /ruta/al/bo-gov-scraper-buho
```

### Problema: "Module 'scraper.catalog' not found"

**Soluci√≥n:**
```bash
# Verifica que __init__.py existe
ls scraper/__init__.py

# Si no existe, cr√©alo:
touch scraper/__init__.py
```

### Problema: "Site ID not found"

**Error:**
```
Sitio no encontrado: gacet_oficial
```

**Soluci√≥n:**
```bash
# Verifica el spelling correcto
python main.py list | grep gaceta

# Debe ser: gaceta_oficial (con 'a' al final)
python main.py info gaceta_oficial
```

### Problema: "Scraper not implemented"

**Mensaje:**
```
‚ö† Scraper no implementado a√∫n
Estado actual: pendiente
```

**Explicaci√≥n:**
- El sitio est√° catalogado pero el scraper a√∫n no se ha desarrollado
- Verifica la prioridad y el roadmap en README.md
- Los scrapers se implementan por olas (Ola 1 primero)

### Problema: "Streamlit no inicia"

**Error:**
```
ModuleNotFoundError: No module named 'streamlit'
```

**Soluci√≥n:**
```bash
# Instalar Streamlit
pip install streamlit

# O reinstalar todas las dependencias
pip install -r requirements.txt
```

### Problema: "YAML parse error"

**Error:**
```
yaml.scanner.ScannerError: ...
```

**Soluci√≥n:**
```bash
# El cat√°logo YAML tiene un error de sintaxis
# Valida el YAML en: https://www.yamllint.com/

# O revierte cambios recientes
git diff config/sites_catalog.yaml
git checkout config/sites_catalog.yaml
```

---

## 8. Consejos y Buenas Pr√°cticas

### Consejo 1: Usa filtros combinados

En lugar de revisar todos los sitios, combina filtros:

```bash
python main.py list --prioridad 1 --tipo normativa
```

### Consejo 2: Exporta a JSON para an√°lisis

```bash
python main.py list --json | jq '.[] | {id: .site_id, nombre: .nombre, estado: .estado_scraper}'
```

### Consejo 3: Valida antes de cambios importantes

```bash
# Antes de modificar el cat√°logo
python main.py validate

# Despu√©s de modificar
python main.py validate
```

### Consejo 4: Usa la UI para exploraci√≥n, CLI para automatizaci√≥n

- **UI (Streamlit):** Exploraci√≥n visual, presentaciones, demos
- **CLI:** Scripts, automatizaci√≥n, cron jobs, pipelines

### Consejo 5: Mant√©n el cat√°logo actualizado

Cuando descubras nuevos sitios:

1. Agr√©galos al cat√°logo YAML
2. Valida: `python main.py validate`
3. Verifica que aparecen: `python main.py list`

---

## 9. Pr√≥ximos Pasos

Una vez te familiarices con el sistema:

1. **Implementar scrapers** (si eres developer)
   - Ver `docs/SCRAPERS.md` (pr√≥ximamente)

2. **Configurar Supabase**
   - Ver `docs/SUPABASE_SETUP.md` (pr√≥ximamente)

3. **Automatizar scraping**
   - Configurar cron jobs
   - Ver `docs/AUTOMATION.md` (pr√≥ximamente)

4. **Integrar con tu aplicaci√≥n**
   - Usar datos exportados
   - Conectar con API de Supabase

---

## 10. Recursos Adicionales

- **README.md** - Gu√≠a general del proyecto
- **docs/SITES_CATALOG.md** - Documentaci√≥n del cat√°logo
- **config/sites_catalog.yaml** - Archivo del cat√°logo

---

**¬øPreguntas o problemas?**
Consulta el README.md o revisa los issues del proyecto.

---

**√öltima actualizaci√≥n:** 2025-01-18
**Versi√≥n:** 1.0.0
