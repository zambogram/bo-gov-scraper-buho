"""
Scraper para Gaceta Constitucional Plurinacional del TCP
FUENTE OFICIAL de jurisprudencia constitucional compilada

Scrapea los tomos anuales de la Gaceta Constitucional desde 2018 hasta el a√±o actual.
"""
from typing import List, Optional, Dict, Any
from pathlib import Path
import re
import logging
from datetime import datetime
from bs4 import BeautifulSoup

from .base_scraper import BaseScraper

logger = logging.getLogger(__name__)


class TCPGacetaScraper(BaseScraper):
    """
    Scraper para Gaceta Constitucional Plurinacional del TCP

    Scrapea tomos compilados de jurisprudencia constitucional por a√±o.
    URL base: https://tcpbolivia.bo/gaceta{a√±o}/
    """

    # A√±os disponibles de la Gaceta (desde 2018 hasta actual)
    A√ëO_INICIO = 2018

    def __init__(self):
        super().__init__('tcp_gaceta')
        logger.info(f"Inicializado scraper para {self.config.nombre}")

        # Calcular a√±o actual
        self.a√±o_actual = datetime.now().year

        logger.info(f"üìö Rango de a√±os: {self.A√ëO_INICIO} - {self.a√±o_actual}")

    def listar_documentos(
        self,
        limite: Optional[int] = None,
        modo: str = "delta",
        pagina: int = 1
    ) -> List[Dict[str, Any]]:
        """
        Listar tomos de la Gaceta Constitucional por a√±o

        Args:
            limite: N√∫mero m√°ximo de documentos
            modo: 'full' o 'delta'
            pagina: No se usa (sin paginaci√≥n)

        Returns:
            Lista de diccionarios con metadata de tomos
        """
        logger.info(f"Listando Gacetas Constitucionales del TCP - modo: {modo}")

        documentos = []

        # Iterar por a√±os (desde el m√°s reciente al m√°s antiguo)
        for a√±o in range(self.a√±o_actual, self.A√ëO_INICIO - 1, -1):
            if limite and len(documentos) >= limite:
                logger.info(f"‚ö†Ô∏è L√≠mite alcanzado ({limite}), deteniendo")
                break

            logger.info(f"\n{'='*60}")
            logger.info(f"üìÖ Procesando Gaceta {a√±o}")
            logger.info(f"{'='*60}")

            docs_a√±o = self._listar_gaceta_a√±o(a√±o)

            # Agregar documentos encontrados
            for doc in docs_a√±o:
                if limite and len(documentos) >= limite:
                    break
                documentos.append(doc)

            logger.info(f"   ‚úì {len(docs_a√±o)} tomos encontrados para {a√±o}")

        logger.info(f"\n{'='*60}")
        logger.info(f"‚úÖ TOTAL: {len(documentos)} tomos de Gaceta Constitucional")
        logger.info(f"{'='*60}")

        return documentos

    def _listar_gaceta_a√±o(self, a√±o: int) -> List[Dict[str, Any]]:
        """
        Listar tomos de la Gaceta para un a√±o espec√≠fico

        Args:
            a√±o: A√±o de la gaceta (ej: 2018, 2019, etc.)

        Returns:
            Lista de documentos (tomos) encontrados
        """
        url = f"{self.config.url_base}/gaceta{a√±o}/"

        logger.info(f"   üìÑ URL: {url}")

        documentos = []

        try:
            response = self.session.get(url, timeout=30, verify=False)

            if response.status_code != 200:
                logger.warning(f"   ‚ö†Ô∏è Status {response.status_code}, saltando a√±o {a√±o}")
                return []

            soup = BeautifulSoup(response.content, 'html.parser')

            # Buscar todos los enlaces a PDFs
            enlaces_pdf = soup.find_all('a', href=lambda x: x and '.pdf' in x.lower())

            logger.info(f"      Enlaces PDF encontrados: {len(enlaces_pdf)}")

            for enlace in enlaces_pdf:
                doc = self._extraer_tomo(enlace, a√±o)
                if doc:
                    documentos.append(doc)

        except Exception as e:
            logger.error(f"   ‚ùå Error procesando a√±o {a√±o}: {e}")

        return documentos

    def _extraer_tomo(self, enlace, a√±o: int) -> Optional[Dict[str, Any]]:
        """
        Extraer metadata de un tomo de la Gaceta

        Args:
            enlace: BeautifulSoup element del enlace <a>
            a√±o: A√±o de la gaceta

        Returns:
            Diccionario con metadata del tomo o None
        """
        try:
            href = enlace.get('href', '')
            texto = enlace.get_text(strip=True)

            if not href:
                return None

            # Construir URL completa
            if href.startswith('http'):
                url_pdf = href
            elif href.startswith('/'):
                url_pdf = f"{self.config.url_base}{href}"
            else:
                url_pdf = f"{self.config.url_base}/{href}"

            # Extraer nombre del archivo desde la URL
            nombre_archivo = url_pdf.split('/')[-1]

            # Detectar tipo de documento
            tipo_doc = "Gaceta Constitucional Plurinacional"
            tomo = None

            # Patrones: TomoI2018.pdf, TomoII2018.pdf, guia2018.pdf
            if 'tomo' in nombre_archivo.lower():
                # Extraer n√∫mero de tomo (I, II, III, IV, V, etc.)
                match_tomo = re.search(r'tomo\s*([IVX]+|[0-9]+)', nombre_archivo, re.I)
                if match_tomo:
                    tomo = match_tomo.group(1).upper()
                    tipo_doc = f"Gaceta Constitucional - Tomo {tomo}"
            elif 'guia' in nombre_archivo.lower():
                tipo_doc = "Gaceta Constitucional - Gu√≠a de Uso"
                tomo = "GUIA"
            elif 'primer' in nombre_archivo.lower() or '1er' in nombre_archivo.lower():
                tipo_doc = "Gaceta Constitucional - Primer Semestre"
                tomo = "1ER_SEM"
            elif 'segundo' in nombre_archivo.lower() or '2do' in nombre_archivo.lower():
                tipo_doc = "Gaceta Constitucional - Segundo Semestre"
                tomo = "2DO_SEM"

            # Generar ID √∫nico
            if tomo:
                id_doc = f"tcp_gaceta_{a√±o}_tomo_{tomo.lower()}"
            else:
                # Usar hash del URL como fallback
                import hashlib
                hash_url = hashlib.md5(url_pdf.encode()).hexdigest()[:8]
                id_doc = f"tcp_gaceta_{a√±o}_{hash_url}"

            # Construir t√≠tulo
            if tomo and tomo != "GUIA":
                titulo = f"Gaceta Constitucional Plurinacional {a√±o} - Tomo {tomo}"
            elif tomo == "GUIA":
                titulo = f"Gu√≠a de Uso - Gaceta Constitucional {a√±o}"
            else:
                titulo = f"Gaceta Constitucional Plurinacional {a√±o}"

            # Sumilla
            sumilla = f"Compilaci√≥n oficial de jurisprudencia constitucional del Tribunal Constitucional Plurinacional - Gesti√≥n {a√±o}"
            if tomo and tomo != "GUIA":
                sumilla += f" (Tomo {tomo})"

            doc = {
                'id_documento': id_doc,
                'tipo_documento': tipo_doc,
                'numero_norma': f"{a√±o}-{tomo}" if tomo else str(a√±o),
                'anio': a√±o,
                'fecha': f"{a√±o}-01-01",  # Fecha aproximada (inicio del a√±o)
                'titulo': titulo,
                'url': url_pdf,
                'sumilla': sumilla,
                'metadata_extra': {
                    "fuente_oficial": "TCP",
                    "tipo_publicacion": "Gaceta Constitucional Plurinacional",
                    "a√±o_gaceta": a√±o,
                    "tomo": tomo,
                    "verificable": True,
                    "metodo_scraping": "real",
                    "tribunal": "Tribunal Constitucional Plurinacional"
                }
            }

            logger.debug(f"      ‚úì {tipo_doc} - {a√±o} - {url_pdf.split('/')[-1]}")
            return doc

        except Exception as e:
            logger.warning(f"      ‚ö†Ô∏è Error extrayendo tomo: {e}")
            return None

    def descargar_pdf(self, url: str, ruta_destino: Path) -> bool:
        """
        Descargar PDF de tomo de la Gaceta con validaci√≥n

        Args:
            url: URL del PDF
            ruta_destino: Ruta local donde guardar

        Returns:
            True si se descarg√≥ correctamente un PDF v√°lido
        """
        logger.info(f"Descargando tomo de Gaceta desde: {url}")

        # Usar el m√©todo de la clase base que ya tiene validaci√≥n
        return self._download_file(url, ruta_destino, timeout=120, validar_pdf=True)
